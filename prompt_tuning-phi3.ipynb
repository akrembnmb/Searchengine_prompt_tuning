{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8378005,"sourceType":"datasetVersion","datasetId":4981799},{"sourceId":8429908,"sourceType":"datasetVersion","datasetId":5020080},{"sourceId":8442271,"sourceType":"datasetVersion","datasetId":5029754},{"sourceId":8542803,"sourceType":"datasetVersion","datasetId":5103796}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install -q peft==0.8.2","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:19:11.537094Z","iopub.execute_input":"2024-06-05T16:19:11.538001Z","iopub.status.idle":"2024-06-05T16:19:25.240590Z","shell.execute_reply.started":"2024-06-05T16:19:11.537963Z","shell.execute_reply":"2024-06-05T16:19:25.239542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%pip install accelerate peft bitsandbytes transformers trl","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.idle":"2024-06-05T16:20:08.053325Z","shell.execute_reply.started":"2024-06-05T16:19:55.356851Z","shell.execute_reply":"2024-06-05T16:20:08.052201Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"microsoft/Phi-3-mini-4k-instruct\"\nNUM_VIRTUAL_TOKENS = 32\nNUM_EPOCHS = 15\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:20:21.745696Z","iopub.execute_input":"2024-06-05T16:20:21.746091Z","iopub.status.idle":"2024-06-05T16:20:21.750949Z","shell.execute_reply.started":"2024-06-05T16:20:21.746054Z","shell.execute_reply":"2024-06-05T16:20:21.750046Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline\n   \n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:20:23.034261Z","iopub.execute_input":"2024-06-05T16:20:23.034620Z","iopub.status.idle":"2024-06-05T16:20:40.282475Z","shell.execute_reply.started":"2024-06-05T16:20:23.034589Z","shell.execute_reply":"2024-06-05T16:20:40.281505Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-06-05 16:20:31.195809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-05 16:20:31.195914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-05 16:20:31.327590: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name, \n    #quantization_config=quant_config,\n    device_map={\"\": 0}, \n    torch_dtype=\"auto\", \n    trust_remote_code=True, \n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)\n\ngeneration_args = {\n    \"max_new_tokens\": 500,\n    \"return_full_text\": False,\n    \"temperature\": 0.0,\n    \"do_sample\": False,\n}\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:02.870245Z","iopub.execute_input":"2024-06-05T16:21:02.870600Z","iopub.status.idle":"2024-06-05T16:21:44.349832Z","shell.execute_reply.started":"2024-06-05T16:21:02.870571Z","shell.execute_reply":"2024-06-05T16:21:44.348919Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"074db4fa5cdb49db85b6e24368178213"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be07148c5bc4a5a8bbc91fcc6695a05"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3783dac8f11e4454895af31c7a5f9b67"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b38fdfc08b54334bba6198ee305ac9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2803d49daaa448fa565b58558dfc213"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8c0e4854b84b989afde5a08b38a70d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c34e58acd9040e398a6aa713779f64a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b620d553904d427c91000b102ee8fd65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d5b1479363148208d0389b4aaa0a8b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de01cb95d69b4e898626e34899e51e7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d88c585cde54ee0bf3346cf9256909e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd2f5f6f9264b8fa4c0df7efa4d7fe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e1554a3b5b847e1aa60ea874e886d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecd83b3fc7e246bfad175027a352756d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"d = data[30]\nimport time\ns=time.time()\nprint(d)\nmessages = [\n    {\"role\": \"user\", \"content\": \"only Answer the question based in  he best answers of this question \"+str(d)},\n    \n]\n\noutput = pipe(messages, **generation_args)\nprint(output[0]['generated_text'])\ne=time.time()\n\nprint(e-s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Process dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('json', data_files=\"/kaggle/input/prompt-data/prompting_data.json\")\nprint (dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:50.120515Z","iopub.execute_input":"2024-06-05T16:21:50.120905Z","iopub.status.idle":"2024-06-05T16:21:50.900853Z","shell.execute_reply.started":"2024-06-05T16:21:50.120874Z","shell.execute_reply":"2024-06-05T16:21:50.899801Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5caed36a72d64114bb215cd526c35e8c"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['prompt'],\n        num_rows: 31\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"data_prompt = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\nprint (data_prompt)\n\ntrain_sample_prompt = data_prompt[\"train\"]\nprint (train_sample_prompt)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:52.707280Z","iopub.execute_input":"2024-06-05T16:21:52.707960Z","iopub.status.idle":"2024-06-05T16:21:52.787215Z","shell.execute_reply.started":"2024-06-05T16:21:52.707927Z","shell.execute_reply":"2024-06-05T16:21:52.786150Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/31 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4efeb64038324a91aeef71b94c8e4f72"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 31\n    })\n})\nDataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 31\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_sample_prompt))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:55.953426Z","iopub.execute_input":"2024-06-05T16:21:55.954039Z","iopub.status.idle":"2024-06-05T16:21:55.958205Z","shell.execute_reply.started":"2024-06-05T16:21:55.954008Z","shell.execute_reply":"2024-06-05T16:21:55.957325Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"31\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prompt Tuning**","metadata":{}},{"cell_type":"code","source":"from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n\n\nprompt_tuning_config = PromptTuningConfig(\n    task_type=TaskType.CAUSAL_LM,\n    prompt_tuning_init=PromptTuningInit.TEXT,\n    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n    prompt_tuning_init_text=\"answer the following question like the provided answer with no explanation\",\n    tokenizer_name_or_path=model_name,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:58.165935Z","iopub.execute_input":"2024-06-05T16:21:58.166373Z","iopub.status.idle":"2024-06-05T16:21:58.216463Z","shell.execute_reply.started":"2024-06-05T16:21:58.166336Z","shell.execute_reply":"2024-06-05T16:21:58.215540Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_model_prompt = get_peft_model(model, prompt_tuning_config)\nprint(peft_model_prompt.print_trainable_parameters())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:22:16.707266Z","iopub.execute_input":"2024-06-05T16:22:16.707673Z","iopub.status.idle":"2024-06-05T16:22:16.850273Z","shell.execute_reply.started":"2024-06-05T16:22:16.707642Z","shell.execute_reply":"2024-06-05T16:22:16.849424Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 98,304 || all params: 3,821,177,856 || trainable%: 0.002572609904708921\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\ndef create_training_arguments(path, learning_rate=0.006, epochs=6):\n    training_args = TrainingArguments(\n        output_dir=path, \n        use_cpu=False, \n        auto_find_batch_size=True, \n        learning_rate= learning_rate, \n        num_train_epochs=epochs\n    )\n    return training_args","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:09.013351Z","iopub.execute_input":"2024-06-05T16:25:09.013683Z","iopub.status.idle":"2024-06-05T16:25:09.019197Z","shell.execute_reply.started":"2024-06-05T16:25:09.013658Z","shell.execute_reply":"2024-06-05T16:25:09.018209Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\n\nworking_dir = \"./\"\n\noutput_directory_prompt =  os.path.join(working_dir, \"prompt_modelv4\")\n\n\nif not os.path.exists(working_dir):\n    os.mkdir(working_dir)\nif not os.path.exists(output_directory_prompt):\n    os.mkdir(output_directory_prompt)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:12.186100Z","iopub.execute_input":"2024-06-05T16:25:12.186798Z","iopub.status.idle":"2024-06-05T16:25:12.192362Z","shell.execute_reply.started":"2024-06-05T16:25:12.186762Z","shell.execute_reply":"2024-06-05T16:25:12.191346Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"training_args_prompt = create_training_arguments(output_directory_prompt, 0.0005, NUM_EPOCHS)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:13.749804Z","iopub.execute_input":"2024-06-05T16:25:13.750192Z","iopub.status.idle":"2024-06-05T16:25:13.789207Z","shell.execute_reply.started":"2024-06-05T16:25:13.750159Z","shell.execute_reply":"2024-06-05T16:25:13.788487Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, DataCollatorForLanguageModeling\ndef create_trainer(model, training_args, train_dataset):\n    trainer = Trainer(\n        model=model, \n        args=training_args, \n        train_dataset=train_dataset, \n        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False) \n    )\n    return trainer\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:15.883606Z","iopub.execute_input":"2024-06-05T16:25:15.884327Z","iopub.status.idle":"2024-06-05T16:25:15.899562Z","shell.execute_reply.started":"2024-06-05T16:25:15.884273Z","shell.execute_reply":"2024-06-05T16:25:15.898746Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer_prompt = create_trainer(peft_model_prompt, training_args_prompt, train_sample_prompt)\ntrainer_prompt.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:18.001893Z","iopub.execute_input":"2024-06-05T16:25:18.002676Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240605_162523-23w6tyi2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/akrembenmbarek/huggingface/runs/23w6tyi2' target=\"_blank\">genial-thunder-20</a></strong> to <a href='https://wandb.ai/akrembenmbarek/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/akrembenmbarek/huggingface' target=\"_blank\">https://wandb.ai/akrembenmbarek/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/akrembenmbarek/huggingface/runs/23w6tyi2' target=\"_blank\">https://wandb.ai/akrembenmbarek/huggingface/runs/23w6tyi2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/465 02:21 < 03:09, 1.40 it/s, Epoch 6.42/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Save the model**","metadata":{}},{"cell_type":"code","source":"trainer_prompt.model.save_pretrained(output_directory_prompt)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load the model**","metadata":{}},{"cell_type":"code","source":"from peft import PeftModel\nloaded_model = PeftModel.from_pretrained(model,\"/kaggle/working/prompt_modelv4\")\nloaded_model = loaded_model.to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(loaded_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnum_params_loaded_model = sum(p.numel() for p in loaded_model.parameters())\nprint(\"loaded model params :\",num_params_loaded_model)\nnum_params = sum(p.numel() for p in model.parameters())\nprint(\"base model params :\",num_params)\nprint(num_params_loaded_model - num_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q = \" question:Which NFL team won Super Bowl 50?\"\nans=\"answer : Denver Broncos\"\ninput_prompt = tokenizer(\"only answer \"+q+ans, return_tensors=\"pt\").to(\"cuda\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"foundational_outputs_prompt = get_outputs(loaded_model, input_prompt, max_new_tokens=100)\n\nprint(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_outputs(model, inputs, max_new_tokens=100):\n    outputs = model.generate(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        max_new_tokens=max_new_tokens,\n        temperature=0.7,\n        top_p=0.95,\n        do_sample=True,\n        repetition_penalty=1.5,\n        early_stopping=True,\n        eos_token_id=tokenizer.eos_token_id\n    )\n    return outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **lora**","metadata":{}},{"cell_type":"code","source":"q= \"question:Which NFL team won Super Bowl 50?\"\na = \"answer : Denver Broncos\"\nprompt = f\"Answer the question based on the answer provided: {q} {a}\"\npipe = pipeline(task=\"question-answering\", model=\"MistralForCausalLM\", tokenizer=tokenizer, max_length=200,temperature = 0)\nresult = pipe(q,a)\nprint(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}}]}